{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nov4mj0m4pZW",
        "colab_type": "text"
      },
      "source": [
        "#Introdução à inteligência artificial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbVJ_cJM4oD9",
        "colab_type": "text"
      },
      "source": [
        "##Projeto final - Tumor cerebral \n",
        "\n",
        "Esse tema de projeto é considerado como desafio, devido à dificuldade de tratamento de dados e devido a arquitetura da rede neural. Pois será utilizada camadas convolucionais que processam imagens de ressonância magnética e detectam a localização do tumor.\n",
        "\n",
        "O dataset escolhido foi: https://figshare.com/articles/brain_tumor_dataset/1512427"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjADTJQ65Cre",
        "colab_type": "text"
      },
      "source": [
        "##Download do dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4tQlbb5eP_x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4f9f598b-c95b-4357-89c3-ec453b0cc21f"
      },
      "source": [
        "!mkdir brain_tumor\n",
        "!wget https://ndownloader.figshare.com/articles/1512427/versions/5\n",
        "!unzip 5\n",
        "!unzip brainTumorDataPublic_1-766.zip -d ./brain_tumor\n",
        "!unzip brainTumorDataPublic_1533-2298.zip -d ./brain_tumor\n",
        "!unzip brainTumorDataPublic_767-1532.zip  -d ./brain_tumor\n",
        "!unzip brainTumorDataPublic_2299-3064.zip  -d ./brain_tumor\n",
        "!rm *.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcLNdAqv5Ls9",
        "colab_type": "text"
      },
      "source": [
        "##Importação das bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWRgHV1s3Kzj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function, division\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.data import Dataset\n",
        "import h5py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGF3Lnop5XRh",
        "colab_type": "text"
      },
      "source": [
        "##Leitura e tratamento das informações"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbCrwQxh55nL",
        "colab_type": "text"
      },
      "source": [
        "Vamos ler somente o primeiro arquivo para verificar qual seu conteúdo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGuUnADZ5_-g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ade2c23d-da03-4cf4-c46e-9ac6de8f3bd1"
      },
      "source": [
        "data_path = \"/content/brain_tumor/\"\n",
        "with h5py.File(data_path+'1.mat', 'r') as f:\n",
        "  print(f.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04TkDFel526h",
        "colab_type": "text"
      },
      "source": [
        "O arquivo contém várias informações: O ID do paciente, a imagem de ressonancia, o label, as coordenada do tumor e a a máscara binaria da localização do tumor\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrPUw_8B6C4s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "34d6af09-cb75-4875-a3e6-a1fb4e3de89f"
      },
      "source": [
        "with h5py.File(data_path+'1.mat', 'r') as f:\n",
        "  print(f['cjdata'].keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nw3xi8Gq58Jy",
        "colab_type": "text"
      },
      "source": [
        "Vamos plotar as imagens de interesse: imagem do exame e a máscara binária.\n",
        "A máscara indica a posição exata do tumor na imagem do exame, ou seja, se fizermos uma operação AND entre a máscara binária e a imagem do exame teremos como resultado uma imagem somente com o tumor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kV3ERIhw4Fqr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "a2b9bd80-c011-43b5-92ca-5fe26a475a16"
      },
      "source": [
        "from numpy import savetxt\n",
        "with h5py.File(data_path+'1.mat', 'r') as f:\n",
        "  plt.imshow(f['cjdata']['tumorMask'],cmap='gray')\n",
        "  plt.figure()\n",
        "  plt.imshow(f['cjdata']['image'],cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrTkIWXa6S80",
        "colab_type": "text"
      },
      "source": [
        "Em seguida, serão lidos todos os arquivos que compoẽm o _dataset_. Como poucas imagens são de tamanhos diferentes, foi decidido retirar imagens diferente de 512x512 pixels.\n",
        "As imagens dos exames são de 11 bits! Portanto, precisamos mudar a escala de 0 a 2047 para uma escala de 0 a 1.\n",
        "\n",
        "Em seguida calculamos a média e desvio padrão do dataset para fazer a normalização."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQyhuL-wPLR9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=[]\n",
        "target=[]\n",
        "test = 0\n",
        "for file_number in range(1,3065):\n",
        "  with h5py.File(data_path+'{}.mat'.format(file_number), 'r') as f:\n",
        "    if(list(torch.from_numpy(f['cjdata']['image'][:]).shape) == [512,512]):\n",
        "      if(list(torch.from_numpy(f['cjdata']['tumorMask'][:]).shape) == [512,512]):\n",
        "        data.append(np.asarray(f['cjdata']['image'][:]))\n",
        "        target.append(np.asarray(f['cjdata']['tumorMask'][:]))\n",
        "\n",
        "tensor_data = torch.tensor(np.asarray(data))\n",
        "tensor_target = torch.tensor(np.asarray(target))\n",
        "\n",
        "mean = 0.\n",
        "std = 0.\n",
        "tensor_data = tensor_data.type(torch.FloatTensor)\n",
        "tensor_data = tensor_data/2047\n",
        "for images in tensor_data:\n",
        "    mean += torch.mean(images)\n",
        "    std += torch.std(images)\n",
        "\n",
        "mean /= len(tensor_data)\n",
        "std /= len(tensor_data)\n",
        "\n",
        "image_dataset = torch.utils.data.TensorDataset(tensor_data,tensor_target) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nX0GJkv77LCE",
        "colab_type": "text"
      },
      "source": [
        "Classe auxiliar para aplicar transformadas em cada dataset separado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQpTtkL2nlp1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ApplyTransform(Dataset):\n",
        "    def __init__(self, dataset, transform=None, target_transform=None):\n",
        "        self.dataset = dataset\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample, target = self.dataset[idx]\n",
        "        if self.transform is not None:\n",
        "            sample = self.transform(sample)\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "        return sample, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yn2FFmNM7WJN",
        "colab_type": "text"
      },
      "source": [
        "##Definição do tamanho de lote e transformações de cada _subset_ do _dataset_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sNjb1c2ofRn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6ecf4bcd-b5fd-42d8-8bcb-a76fec09d148"
      },
      "source": [
        "# Porcentagem da quantidade de imagem que será definida para uso como validação e teste\n",
        "# TODO: Defina o valor percentual que esteja entre 0 a 1\n",
        "test_valid_size = 0.4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4IL-mbWlonH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: Quantas amostras por lote \n",
        "batch_size = 4\n",
        "\n",
        "# Define as transformações, fique a vontade para adicionar mais transformações!!!\n",
        "train_transform = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize(256),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Lambda(lambda x: x.repeat(3, 1, 1)),\n",
        "        transforms.Normalize(mean, std)])\n",
        "valid_transform = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize(256),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Lambda(lambda x: x.repeat(3, 1, 1)),\n",
        "        transforms.Normalize(mean, std)])\n",
        "test_transform = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize(256),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Lambda(lambda x: x.repeat(3, 1, 1)),\n",
        "        transforms.Normalize(mean, std)])\n",
        "target_transform = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize(256),\n",
        "        transforms.ToTensor()])\n",
        "# Obter índices de treinamento que serão usados para validação\n",
        "num_train = len(image_dataset)\n",
        "indices = list(range(num_train))\n",
        "np.random.shuffle(indices)\n",
        "split = int(np.floor(test_valid_size * num_train))\n",
        "train_idx, valid_idx , test_idx = indices[split:], indices[:int(np.floor(split/2))], indices[int(np.floor(split/2)):split]\n",
        "\n",
        "# Definir amostradores para obter lotes de treinamento e validação\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "test_sampler = SubsetRandomSampler(test_idx)\n",
        "\n",
        "# Aplica as transformações para o treino e validação\n",
        "train_dataset = ApplyTransform(image_dataset, transform=train_transform, target_transform=target_transform)\n",
        "valid_dataset = ApplyTransform(image_dataset, transform=valid_transform,target_transform=target_transform)\n",
        "test_dataset = ApplyTransform(image_dataset, transform=test_transform,target_transform=target_transform)\n",
        "\n",
        "# Preparar carregadores de dados (combinar conjunto de dados e amostrador)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
        "    sampler=train_sampler)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, \n",
        "    sampler=valid_sampler)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
        "    sampler=test_sampler)\n",
        "\n",
        "data_loader = {'train':train_loader,'val':valid_loader,'test':test_loader}\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKklb8e-7mhg",
        "colab_type": "text"
      },
      "source": [
        "##Definição e treinamento do modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBlwhJef4Wvi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_loss = 1e10\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Época {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Cada época tem uma fase de treino e validação\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Modelo em treinamento\n",
        "            else:\n",
        "                model.eval()   # Modelo em avaliação\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            for inputs, labels in data_loader[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # Zera o gradiente do otimizador\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Analisa somente as perdas se for no treinamento\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    #y_pred = outputs.data.cpu().numpy().ravel()\n",
        "                    #y_true = labels.data.cpu().numpy().ravel()\n",
        "\n",
        "                    # 'loss.backward()' + 'optimizer.step()' somente no treinamento\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # Estatisticas\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss \n",
        "\n",
        "            print('{} Perda: {:.4f}'.format(\n",
        "                phase, epoch_loss))\n",
        "\n",
        "            # Copia o modelo\n",
        "            if phase == 'val' and epoch_loss < best_loss:\n",
        "                best_loss = epoch_loss\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Treinamento completo em {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    torch.save(best_model_wts,\"model.pt\")\n",
        "\n",
        "    # Carrega os pesos do melhor modelo\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fmvXQ6U9vbd",
        "colab_type": "text"
      },
      "source": [
        "Para a definição de uma rede neural para segmentação, você pode usar as seguintes redes pré-treinadas: [U-Net](https://pytorch.org/hub/mateuszbuda_brain-segmentation-pytorch_unet/), [DeepLabv3](https://pytorch.org/hub/pytorch_vision_deeplabv3_resnet101/) ou [FCN](https://pytorch.org/hub/pytorch_vision_fcn_resnet101/). Como você tambem pode criar uma do zero e aproveitando partes pré-treinadas de outras redes como a [VGG](https://pytorch.org/docs/stable/torchvision/models.html#torchvision.models.vgg11), [Resnet](https://pytorch.org/docs/stable/torchvision/models.html#torchvision.models.resnet18) e etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oay02vf4715D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: Defina aqui qual seu modelo\n",
        "model = NotImplemented\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "                      \n",
        "# Move o modelo para o dispositivo disponivel\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = NotImplemented\n",
        "optimizer = NotImplemented\n",
        "exp_lr_scheduler = NotImplemented"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mb4n-pPW_rGi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e48fb123-4f77-4ca8-8a71-4a25d97e9d18"
      },
      "source": [
        "model = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBWJzZvI7_lN",
        "colab_type": "text"
      },
      "source": [
        "##Teste o modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNilikV5DC6W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eee5b962-6cbe-48a6-8b5e-288c3876d7cb"
      },
      "source": [
        "# Carrega o modelo \n",
        "file_name = \"model.pt\"\n",
        "model.load_state_dict(torch.load(file_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3ilrCuh8DVN",
        "colab_type": "text"
      },
      "source": [
        "Vamos ler uma __imagem__ e __label__ do dataset de teste por vez e plotar para visualizar. Depois faremos a inferência dessa imagem e visualizaremos o resultado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FOCC8mcSBfl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_iter = iter(test_loader)\n",
        "image, label = data_iter.next()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWwAkgCwk25M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "1fda180b-4c8e-443f-f122-4d601ec3be74"
      },
      "source": [
        "#Visualização da máscara binária\n",
        "plt.imshow(label[0][0],cmap=\"gray\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7B8o1Aowk5Uf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "cd075289-5932-44e8-cfdf-253f87e7c8ae"
      },
      "source": [
        "#Visualização da imagem do exame\n",
        "plt.imshow(image[0][0],cmap=\"gray\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVnF0p0cpceC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Relizar a inferência\n",
        "model.eval()\n",
        "out = model(image.cuda())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46RdzAXPleft",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "abbec7e7-3d54-4322-deb4-721cba71aa15"
      },
      "source": [
        "#Visualizar o resultado\n",
        "output = (out[0][0]).cpu().detach().numpy()\n",
        "plt.imshow(np.asarray(output),cmap=\"gray\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2f2hPLzgjaa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Novo_dataset_tumor.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
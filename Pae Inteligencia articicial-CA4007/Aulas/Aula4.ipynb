{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aula4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqymqR7Y7w6u",
        "colab_type": "text"
      },
      "source": [
        "#Introdução à inteligência artificial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRh0y4kd71l3",
        "colab_type": "text"
      },
      "source": [
        "## Aula 4 - Como treinar uma rede neural artificial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XS08GCIa-Lp2",
        "colab_type": "text"
      },
      "source": [
        "A rede que construímos na aula anterior não é tão inteligente, ela não sabe nada sobre nossos dígitos manuscritos. As redes neurais com ativações não lineares funcionam como aproximadores de funções universais. Há alguma função que mapeia sua entrada para a saída. Por exemplo, imagens de dígitos manuscritos para probabilidades de classe. O poder das redes neurais é que podemos treiná-las para aproximar essa função e basicamente qualquer função que tenha dados e tempo de computação suficientes.\n",
        "\n",
        "A princípio, a rede é ingênua, não conhece a função que mapeia as entradas para as saídas. Nós treinamos a rede, mostrando exemplos de dados reais e, em seguida, ajustando os parâmetros da rede para que ela se aproxime dessa função.\n",
        "\n",
        "Para encontrar esses parâmetros, precisamos saber quão mal a rede está prevendo as saídas reais. Para isso, calculamos uma **função de perda** (também chamada de custo), uma medida do nosso erro de previsão. Por exemplo, a perda quadrática média é frequentemente usada em problemas de regressão e classificação binária\n",
        "\n",
        "$$\n",
        "\\large C = \\frac{1}{2n}\\sum_i^n{\\left(y_i - \\hat{y}_i\\right)^2}\n",
        "$$\n",
        "\n",
        "onde $ n $ é o número de exemplos de treinamento, $ y_i $ são os rótulos verdadeiros e $ \\hat {y}_i $ são os rótulos previstos.\n",
        "\n",
        "Ao minimizar essa perda com relação aos parâmetros de rede, podemos encontrar configurações em que a perda é mínima e a rede é capaz de prever as etiquetas corretas com alta precisão. Achamos esse mínimo usando um processo chamado **descida de gradiente**. O gradiente é a inclinação da função de perda e aponta na direção da mudança mais rápida. Para chegar ao mínimo na menor quantidade de tempo, queremos seguir o gradiente (para baixo). Você pode pensar nisso como descer uma montanha seguindo a ladeira mais íngreme até a base.\n",
        "\n",
        "<div align=center>\n",
        "<img src='https://blog.paperspace.com/content/images/2018/05/fastlr.png' width=450px>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCu07nuSAOys",
        "colab_type": "text"
      },
      "source": [
        "### Retropropagação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tP-ItqeAAEDi",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Para redes de camada única, a descida em gradiente é simples de implementar. No entanto, é mais complicado para redes neurais mais profundas e multicamadas como a que construímos. Complicado o suficiente para levar cerca de 30 anos até os pesquisadores descobrirem como treinar redes multicamadas.\n",
        "\n",
        "O treinamento de redes multicamadas é feito por meio de **retropropagação**, que é realmente apenas uma aplicação da regra da cadeia de cálculo. É mais fácil entender se convertermos uma rede de duas camadas em uma representação gráfica.\n",
        "\n",
        "<div align=center>\n",
        "<img src='https://miro.medium.com/max/1485/0*ZlMNumCS7Z1wQgax.' width=450px>\n",
        "\n",
        "Figura 1 - Passagem direta\n",
        "</div>\n",
        "\n",
        "\n",
        "<div align=center>\n",
        "<img src='https://miro.medium.com/max/1413/0*U7Zg0fqsv4dN-TFO.' width=450px>\n",
        "\n",
        "Figura 2 - Passagem inversa em passos\n",
        "</div>\n",
        "\n",
        "<div align=center>\n",
        "<img src='https://miro.medium.com/max/1413/0*VHvavv03ptQ4jBiP.' width=450px>\n",
        "\n",
        "Figura 3 - Passagem inversa\n",
        "</div>\n",
        "\n",
        "\n",
        "Na passagem direta pela rede, nossos dados e operações vão de baixo para cima aqui. Passamos a entrada $ x $ por uma transformação linear $ L_1 $ com pesos $ W_1 $ e viés $ b_1 $. A saída passa pela operação sigmóide $ S $ e outra transformação linear $ L_2 $. Finalmente, calculamos a perda $ C $. Usamos a perda como uma medida de quão ruins são as previsões da rede. O objetivo, então, é ajustar os pesos e desvios para minimizar a perda.\n",
        "\n",
        "Para treinar os pesos com descida de gradiente, propagamos o gradiente da perda para trás através da rede. Cada operação possui algum gradiente entre as entradas e saídas. À medida que enviamos os gradientes para trás, multiplicamos o gradiente de entrada pelo gradiente da operação. Matematicamente, isso é realmente apenas o cálculo do gradiente da perda com relação aos pesos usando a regra da cadeia.\n",
        "\n",
        "$$\n",
        "\\large \\frac{\\partial C}{\\partial W_1} = \\frac{\\partial L_1}{\\partial W_1} \\frac{\\partial S}{\\partial L_1} \\frac{\\partial L_2}{\\partial S} \\frac{\\partial C}{\\partial L_2}\n",
        "$$\n",
        "\n",
        "Atualizamos nossos pesos usando esse gradiente com alguma taxa de aprendizado $ \\alpha $.\n",
        "\n",
        "$$\n",
        "\\large W^\\prime_1 = W_1 - \\alpha \\frac{\\partial C}{\\partial W_1}\n",
        "$$\n",
        "\n",
        "A taxa de aprendizado $ \\alpha $ é configurada de forma que as etapas de atualização de peso sejam pequenas o suficiente para que o método iterativo seja estabelecido no mínimo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VN3gFIYeylTh",
        "colab_type": "text"
      },
      "source": [
        "### Perdas no PyTorch\n",
        "\n",
        "Vamos começar vendo como calculamos a perda com o PyTorch. Através do módulo `nn`, o PyTorch fornece perdas como a perda de entropia cruzada (` nn.CrossEntropyLoss`). Você geralmente verá a perda atribuída ao 'critério'. Conforme observado na última parte, com um problema de classificação como MNIST, estamos usando a função softmax para prever probabilidades de classe. Com uma saída softmax, você deseja usar a entropia cruzada como perda. Para realmente calcular a perda, primeiro defina o critério e depois passe a saída da sua rede e os rótulos corretos.\n",
        "\n",
        "Algo realmente importante a ser observado aqui. Examinando [a documentação para `nn.CrossEntropyLoss`](https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss),\n",
        "\n",
        "> Este critério combina `nn.LogSoftmax()` e `nn.NLLLoss()` em uma única classe.\n",
        ">\n",
        "> A entrada deve conter pontuações para cada classe.\n",
        "\n",
        "Isso significa que precisamos passar a produção bruta de nossa rede para a perda, não a produção da função softmax. Essa saída bruta geralmente é chamada de *logits* ou *scores*. Usamos os logits porque o softmax fornece probabilidades que geralmente ficam muito próximas de zero ou um, mas os números de ponto flutuante não podem representar com precisão valores próximos de zero ou um ([leia mais aqui](https://docs.python.org/3/tutorial/floatingpoint.html)). Geralmente, é melhor evitar cálculos com probabilidades, normalmente usamos probabilidades de log."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ve0FWuBL-K75",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "\n",
        "# Defina uma transformação para normalizar os dados\n",
        "transform = transforms.Compose([\n",
        "transforms.ToTensor(), transforms.Normalize([0.5], [0.5])])\n",
        "\n",
        "# Faça o download e carregue os dados de treinamento\n",
        "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ej_cDNTJ1AKq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Construa uma rede neural\n",
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10))\n",
        "\n",
        "# Defina a perda\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Pega a informação\n",
        "images, labels = next(iter(trainloader))\n",
        "# \"Achata\" a imagem\n",
        "images = images.view(images.shape[0], -1)\n",
        "\n",
        "# Passe para frente, obtenha nossos logits\n",
        "logits = model(images)\n",
        "# Calcular a perda com os logits e os rótulos\n",
        "loss = criterion(logits, labels)\n",
        "\n",
        "print(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dC9C2Kc23Ovh",
        "colab_type": "text"
      },
      "source": [
        "É mais conveniente criar o modelo com uma saída log-softmax usando `nn.LogSoftmax` ([documentação](https://pytorch.org/docs/stable/nn.html#torch.nn.LogSoftmax)). Então você pode obter as probabilidades reais pegando o exponencial `torch.exp (output)`. Com uma saída log-softmax, você deseja usar a perda de probabilidade de log negativa, `nn.NLLLoss` ([documentação](https://pytorch.org/docs/stable/nn.html#torch.nn.NLLLoss)) .\n",
        "\n",
        "> **Exercício:** Construa um modelo que retorne o log-softmax como saída (lembrando que o parâmetro dim=1) e calcule a perda usando a perda de probabilidade de log negativa."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SN2TxcjU3OX0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Construa uma rede neural \n",
        "model = None\n",
        "\n",
        "# Defina a perda\n",
        "criterion = None\n",
        "\n",
        "# Pega a informação\n",
        "images, labels = next(iter(trainloader))\n",
        "# \"Achata\" a imagem\n",
        "images = images.view(images.shape[0], -1)\n",
        "\n",
        "# Passe para frente, obtenha as probabilidades log\n",
        "logps = model(images)\n",
        "# Calcular a perda com as probabilidades log e os rótulos\n",
        "loss = criterion(logps, labels)\n",
        "\n",
        "print(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eT4nb3u_4m4B",
        "colab_type": "text"
      },
      "source": [
        "### Autograd\n",
        "\n",
        "Agora que sabemos como calcular uma perda, como a usamos para realizar a retropropagação? O PyTorch fornece um módulo, `autograd`, para calcular automaticamente os gradientes dos tensores. Podemos usá-lo para calcular os gradientes de todos os nossos parâmetros em relação à perda. O Autograd trabalha mantendo o controle das operações realizadas nos tensores e depois retrocedendo nessas operações, calculando gradientes ao longo do caminho. Para garantir que o PyTorch acompanhe as operações em um tensor e calcule os gradientes, você precisa definir `require_grad = True` em um tensor. Você pode fazer isso na criação com a palavra-chave `require_grad` ou a qualquer momento com` x.requires_grad_(True) `.\n",
        "\n",
        "Você pode desativar gradientes para um bloco de código com o conteúdo `torch.no_grad()`:\n",
        "```python\n",
        "x = torch.zeros(1, requires_grad=True)\n",
        ">>> with torch.no_grad():\n",
        "...     y = x * 2\n",
        ">>> y.requires_grad\n",
        "False\n",
        "```\n",
        "\n",
        "Além disso, você pode ativar ou desativar gradientes completamente com `torch.set_grad_enabled(True|False)`.\n",
        "\n",
        "Os gradientes são calculados com relação a alguma variável `z` com` z.backward() `. Isso faz um retrocesso nas operações que criaram `z`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uxi5R_Hs7pn6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.randn(2,2, requires_grad=True)\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjFUhmAU5WFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = x**2\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lcDihAP5d8f",
        "colab_type": "text"
      },
      "source": [
        "Abaixo podemos ver a operação que criou `y`, uma operação de potência `PowBackward0`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUCNfIuA5f0y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## grad_fn mostra a função que gerou essa variável\n",
        "print(y.grad_fn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBe5_B-k5whE",
        "colab_type": "text"
      },
      "source": [
        "O módulo autograd monitora essas operações e sabe como calcular o gradiente para cada uma. Dessa forma, é capaz de calcular os gradientes para uma cadeia de operações, com relação a qualquer tensor. Vamos reduzir o tensor `y` para um valor escalar, a média."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2yEOM-x5m3-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z = y.mean()\n",
        "print(z)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkHoyOkW548S",
        "colab_type": "text"
      },
      "source": [
        "Você pode verificar os gradientes para `x` e `y`, mas eles estão vazios no momento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfjrjfpT59kW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(x.grad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHH0lroq6FJK",
        "colab_type": "text"
      },
      "source": [
        "Para calcular os gradientes, você precisa executar o método `.backward` em uma variável, `z` por exemplo. Isso calculará o gradiente para `z` com relação a `x`\n",
        "\n",
        "$$\n",
        "\\frac{\\partial z}{\\partial x} = \\frac{\\partial}{\\partial x}\\left[\\frac{1}{n}\\sum_i^n x_i^2\\right] = \\frac{x}{2}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hE_IOjve6HnG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z.backward()\n",
        "print(x.grad)\n",
        "print(x/2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOaWBxnj9kxs",
        "colab_type": "text"
      },
      "source": [
        "Esses cálculos de gradientes são particularmente úteis para redes neurais. Para o treinamento, precisamos dos gradientes dos pesos em relação ao custo. Com o PyTorch, executamos os dados adiante pela rede para calcular a perda e depois retrocedemos para calcular os gradientes em relação à perda. Quando tivermos os gradientes, podemos fazer um passo de descida de gradiente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBKGwdbK9uLN",
        "colab_type": "text"
      },
      "source": [
        "### Perda e Autograd juntos\n",
        "\n",
        "Quando criamos uma rede com o PyTorch, todos os parâmetros são inicializados com `require_grad = True`. Isso significa que, quando calculamos a perda e chamamos `loss.backward()`, os gradientes para os parâmetros são calculados. Esses gradientes são usados para atualizar os pesos com a descida do gradiente. Abaixo, você pode ver um exemplo de cálculo dos gradientes usando um passe para trás."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2HtwP_59lN3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Criando a rede neural e definindo o critério\n",
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "images, labels = next(iter(trainloader))\n",
        "images = images.view(images.shape[0], -1)\n",
        "\n",
        "logps = model(images)\n",
        "loss = criterion(logps, labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOUv7KOF-DIu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Antes do passe inverso: \\n', model[0].weight.grad)\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "print('Depois do passe inverso: \\n', model[0].weight.grad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vol5MY9J-PyM",
        "colab_type": "text"
      },
      "source": [
        "### Treinando a rede!\n",
        "\n",
        "Há uma última peça que precisamos para começar o treinamento, um otimizador que usaremos para atualizar os pesos com os gradientes. Nós obtemos isso do pacote PyTorch [`optim`](https://pytorch.org/docs/stable/optim.html). Por exemplo, podemos usar a descida de gradiente estocástico com `optim.SGD`. Você pode ver como definir um otimizador abaixo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ticw_2LB-Zlb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import optim\n",
        "\n",
        "# Os otimizadores exigem os parâmetros para otimizar e uma taxa de aprendizado\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "to9nx2cC-6Xx",
        "colab_type": "text"
      },
      "source": [
        "Agora sabemos como usar todas as partes individuais, então é hora de ver como elas funcionam juntas. Vamos considerar apenas uma etapa de aprendizado antes de percorrer todos os dados. O processo geral com o PyTorch:\n",
        "\n",
        "* Faça um passe para frente através da rede\n",
        "* Use a saída de rede para calcular a perda\n",
        "* Execute um retrocesso na rede com `loss.backward()` para calcular os gradientes\n",
        "* Dê um passo com o otimizador para atualizar os pesos\n",
        "\n",
        "Abaixo, vou seguir uma etapa do treinamento e imprimir os pesos e gradientes para que você possa ver como isso muda. Note que eu tenho uma linha de código `optimizer.zero_grad()`. Quando você faz várias passagens para trás com os mesmos parâmetros, os gradientes são acumulados. Isso significa que você precisa zerar os gradientes em cada passe de treinamento ou reter gradientes dos lotes de treinamento anteriores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfSSrcDM_M7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Pesos iniciais - ', model[0].weight)\n",
        "\n",
        "images, labels = next(iter(trainloader))\n",
        "images.resize_(64, 784)\n",
        "\n",
        "# Limpe os gradientes, faça isso porque os gradientes são acumulados\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# Passe para frente, depois para trás e atualize pesos\n",
        "output = model(images)\n",
        "loss = criterion(output, labels)\n",
        "loss.backward()\n",
        "print('Gradiente -', model[0].weight.grad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuS1vLVr_dHU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dê um passo de atualização e atualiza os novos pesos\n",
        "optimizer.step()\n",
        "print('Pesos atualizados - ', model[0].weight)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RrqMdzO_1kG",
        "colab_type": "text"
      },
      "source": [
        "### Treinamento de verdade\n",
        "\n",
        "Agora vamos colocar esse algoritmo em um loop para que possamos percorrer todas as imagens. Em alguma nomenclatura, uma passagem por todo o conjunto de dados é chamada de *época*. Então, aqui vamos percorrer o `trainloader 'para obter nossos lotes de treinamento. Para cada lote, faremos um passe de treinamento em que calculamos a perda, passamos para trás e atualizamos os pesos.\n",
        "\n",
        "> **Exercício:** Implemente o passe de treinamento para nossa rede. Se você o implementou corretamente, a perda de treinamento diminui a cada época."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xys1Tvah_82H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = None\n",
        "\n",
        "criterion = None\n",
        "optimizer = None\n",
        "\n",
        "epochs = 5\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in trainloader:\n",
        "        images = images.view(images.shape[0], -1)\n",
        "    \n",
        "        # TODO: Passe de treino\n",
        "        # Limpe o gradiente do otimizador\n",
        "        # Faça um passe pra frente usando o modelo e as imagens, obtendo as probabilidades log\n",
        "        # Use o critério com as probabilidades e os 'labels, obtendo a perda \"loss\"\n",
        "        # Realize um \"passe pra trás\" na perda\n",
        "        # Dê um passo no otimizador\n",
        "                \n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(f\"Perda de treinamento: {running_loss/len(trainloader)}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8VY9UnlAJUh",
        "colab_type": "text"
      },
      "source": [
        "Com a rede treinada, podemos verificar suas previsões."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyA3rbWyAx9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Função auxiliar\n",
        "def view_classify(img, ps, version=\"MNIST\"):\n",
        "    ps = ps.data.numpy().squeeze()\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
        "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
        "    ax1.axis('off')\n",
        "    ax2.barh(np.arange(10), ps)\n",
        "    ax2.set_aspect(0.1)\n",
        "    ax2.set_yticks(np.arange(10))\n",
        "    if version == \"MNIST\":\n",
        "        ax2.set_yticklabels(np.arange(10))\n",
        "    ax2.set_title('Probabilidade de classe')\n",
        "    ax2.set_xlim(0, 1.1)\n",
        "\n",
        "    plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWDh3326AKaj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "images, labels = next(iter(trainloader))\n",
        "\n",
        "img = images[1].view(1, 784)\n",
        "# Desative gradientes para acelerar esta parte\n",
        "with torch.no_grad():\n",
        "    logps = model(img)\n",
        "\n",
        "# Os resultados da rede são probabilidades de log, precisam ser exponenciais para probabilidades\n",
        "ps = torch.exp(logps)\n",
        "view_classify(img.view(1, 28, 28), ps)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
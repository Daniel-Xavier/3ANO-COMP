{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aula5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yq9AzG-TcjKo",
        "colab_type": "text"
      },
      "source": [
        "#Introdução à inteligência artificial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMZLQOtxck9F",
        "colab_type": "text"
      },
      "source": [
        "## Aula 5 - Inferência e validação "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drBeY2aWd640",
        "colab_type": "text"
      },
      "source": [
        "Agora que você possui uma rede treinada, pode usá-la para fazer previsões. Isso geralmente é chamado de **inferência**, um termo emprestado da estatística. No entanto, as redes neurais tendem a ter um desempenho *muito bom* nos dados de treinamento e não são capazes de generalizar para dados que não foram vistos antes. Isso é chamado de _overfitting_ e prejudica o desempenho da inferência. Para testar o ajuste excessivo durante o treinamento, medimos o desempenho em dados que não estão no conjunto de treinamento chamado **conjunto de validação**. Evitamos o ajuste excessivo através da regularização, como o _Dropout_, enquanto monitoramos o desempenho da validação durante o treinamento. \n",
        "\n",
        "Como sempre, vamos começar carregando o conjunto de dados através do _torchvision_. Você aprenderá mais sobre a _torchvision_ e o carregamento de dados em uma parte posterior. Desta vez, aproveitaremos o conjunto de testes que você pode obter configurando `train = False` aqui:\n",
        "\n",
        "```python\n",
        "testset = datasets.FashionMNIST ('~ / .pytorch / F_MNIST_data /', download = True, train = False, transform = transform)\n",
        "```\n",
        "\n",
        "O conjunto de teste contém imagens exatamente como o conjunto de treinamento. Normalmente, você verá de 10 a 20% do conjunto de dados original mantido para teste e validação, sendo o restante usado para treinamento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6C7qlZpd8Rn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn, optim\n",
        "import time\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Defina uma transformação para normalizar os dados\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5], [0.5])])\n",
        "\n",
        "# Faça o download e carregue os dados de treinamento\n",
        "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Faça o download e carregue os dados de teste\n",
        "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0qDZZJYg-mz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Crie um modelo\n",
        "model = nn.Sequential(nn.Linear(784, 256),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(256, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10),\n",
        "                      nn.LogSoftmax(dim=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyWPwkjXGYgA",
        "colab_type": "text"
      },
      "source": [
        "O objetivo da validação é medir o desempenho do modelo em dados que não fazem parte do conjunto de treinamento. O desempenho aqui depende do desenvolvedor definir. Normalmente, isso é apenas precisão, a porcentagem de classes que a rede previu corretamente. Outras opções são [precisão e revocação](https://pt.wikipedia.org/wiki/Precis%C3%A3o_e_revoca%C3%A7%C3%A3o) e a taxa de erros entre as 5 principais. Vamos nos concentrar na precisão aqui. Primeiro, eu passo adiante com um lote do conjunto de teste."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1V4XEvAF9P3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pega a informação\n",
        "images, labels = next(iter(testloader))\n",
        "\n",
        "# \"Achata\" a imagem\n",
        "images = images.view(images.shape[0], -1)\n",
        "\n",
        "# Passe para frente, obtenha nossos logits\n",
        "ps = torch.exp(model(images))\n",
        "\n",
        "# Verificar se existem 10 possibilidade para as 64 imagens\n",
        "print(ps.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQdd1gn6G7yQ",
        "colab_type": "text"
      },
      "source": [
        "Com as probabilidades, podemos obter a classe mais provável usando o método `ps.topk`. Isso retorna os valores mais altos de $ k $. Como queremos apenas a classe mais provável, podemos usar o `ps.topk(1)`. Isso retorna uma tupla dos principais valores de $ k $ e dos principais índices de $ k $. Se o valor mais alto for o quinto elemento, retornaremos 4 como o índice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zWCCjeIGLTM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "top_p, top_class = ps.topk(1, dim=1)\n",
        "# Veja as classes mais prováveis para os 10 primeiros exemplos\n",
        "print(top_class[:10,:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PU5Bl3LQJLOu",
        "colab_type": "text"
      },
      "source": [
        "Agora podemos verificar se as classes previstas correspondem aos rótulos. Isso é simples, equacionando `top_class` e `labels`, mas temos que ter cuidado com as formas. Aqui `top_class` é um tensor 2D com forma `(64, 1)` enquanto `labels` é 1D com forma `(64)`. Para que a igualdade funcione da maneira que queremos, `top_class` e` labels` devem ter a mesma forma.\n",
        "\n",
        "Se nós fizermos\n",
        "\n",
        "`` python\n",
        "equals = top_class == labels\n",
        "`` ``\n",
        "\n",
        "`equals` terá forma `(64, 64) `, tente você mesmo. O que ele está fazendo é comparar o elemento em cada linha de `top_class` com cada elemento em` labels`, que retorna 64 valores booleanos True/False para cada linha."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHncouBIHJBK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "equals = top_class == labels.view(*top_class.shape)\n",
        "print(equals)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3_Lt-6lJl_l",
        "colab_type": "text"
      },
      "source": [
        "Agora precisamos calcular a porcentagem de previsões corretas. 'equals' tem valores binários, 0 ou 1. Isso significa que, se somarmos todos os valores e dividirmos pelo número de valores, obteremos a porcentagem de previsões corretas. Esta é a mesma operação que a média, para que possamos obter a precisão com uma chamada para `torch.mean`. Se fosse assim tão simples. Se você tentar `torch.mean(equals)`, você receberá um erro\n",
        "\n",
        "```\n",
        "RuntimeError: mean is not implemented for type torch.ByteTensor\n",
        "```\n",
        "\n",
        "Isso acontece porque `equals` tem o tipo `torch.ByteTensor`, mas o `torch.mean` não é implementado para tensores com esse tipo. Então, precisamos converter \"equals\" em um tensor de float. Note que quando pegamos o `torch.mean`, ele retorna um tensor escalar, para obter o valor real como um float, precisamos fazer o `accuracy.item()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JANNZp71JdXj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
        "print(f'Precisão: {accuracy.item()*100}%')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmw38EMqLped",
        "colab_type": "text"
      },
      "source": [
        "A rede não é treinada, por isso está fazendo suposições aleatórias e devemos ver uma precisão em torno de 10%. Agora vamos treinar nossa rede e incluir nosso passe de validação para que possamos medir o desempenho da rede no conjunto de testes. Como não estamos atualizando nossos parâmetros no passo de validação, podemos acelerar nosso código desativando gradientes usando `torch.no_grad()`:\n",
        "\n",
        "``` python\n",
        "# desativar gradientes\n",
        "with torch.no_grad():\n",
        "     # passe de validação aqui\n",
        "     for images, labels in testloader:\n",
        "        ...\n",
        "```\n",
        "\n",
        "> **Exemplo:** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nVfP7GiKDVN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = nn.Sequential(nn.Linear(784, 256),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(256, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
        "\n",
        "epochs = 5\n",
        "\n",
        "train_losses, test_losses = [], []\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in trainloader:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        images = images.view(images.shape[0], -1)\n",
        "        log_ps = model(images)\n",
        "        loss = criterion(log_ps, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        \n",
        "    else:\n",
        "        test_loss=0\n",
        "        accuracy=0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in testloader:\n",
        "                images = images.view(images.shape[0], -1)\n",
        "                log_ps = model(images)\n",
        "                test_loss += criterion(log_ps, labels)\n",
        "                ps = torch.exp(log_ps)\n",
        "                top_p, top_class = ps.topk(1, dim=1)\n",
        "                equals = top_class == labels.view(*top_class.shape)\n",
        "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
        "\n",
        "        train_losses.append(running_loss/len(trainloader))\n",
        "        test_losses.append(test_loss/len(testloader))\n",
        "\n",
        "        print(\"Época: {}/{}.. \".format(e+1, epochs),\n",
        "              \"Perda de treino: {:.3f}.. \".format(running_loss/len(trainloader)),\n",
        "              \"Perda de teste: {:.3f}.. \".format(test_loss/len(testloader)),\n",
        "              \"Precisão de teste: {:.3f}\".format(accuracy/len(testloader)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q059ZMCCyOf7",
        "colab_type": "text"
      },
      "source": [
        "## Overfitting\n",
        "\n",
        "Se observarmos as perdas de treinamento e validação à medida que treinamos a rede, podemos ver um fenômeno conhecido como overfitting (sobreajuste).\n",
        "\n",
        "<div align=center>\n",
        "<img src=\"http://numpy.d2l.ai/_images/capacity_vs_error.svg\">\n",
        "</div>\n",
        "\n",
        "A rede aprende o conjunto de treinamento cada vez melhor, resultando em menores perdas de treinamento. No entanto, ele começa a ter problemas para generalizar dados fora do conjunto de treinamento, levando ao aumento da perda de validação. O objetivo final de qualquer modelo de aprendizado profundo é fazer previsões sobre novos dados; portanto, devemos nos esforçar para obter a menor perda de validação possível. Uma opção é usar a versão do modelo com a menor perda de validação, aqui a de 8 a 10 épocas de treinamento. Essa estratégia é chamada *parada antecipada*. Na prática, você salvaria o modelo frequentemente enquanto treinava e depois escolheria o modelo com a menor perda de validação.\n",
        "\n",
        "O método mais comum para reduzir o excesso de ajustes (fora da parada antecipada) é o *dropout*, onde eliminamos aleatoriamente as unidades de entrada. Isso força a rede a compartilhar informações entre pesos, aumentando sua capacidade de generalizar para novos dados. Adicionar dropout no PyTorch é simples usando o módulo [`nn.Dropout`](https://pytorch.org/docs/stable/nn.html#torch.nn.Dropout).\n",
        "\n",
        "```python\n",
        "model = nn.Sequential(nn.Linear(784, 256),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Dropout(p=0.2),\n",
        "                      nn.Linear(256, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Dropout(p=0.2),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Dropout(p=0.2),\n",
        "                      nn.Linear(64, 10),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "``` \n",
        "\n",
        "Durante o treinamento, queremos usar o _dropout_ para evitar o ajuste excessivo, mas durante a inferência, queremos usar toda a rede. Portanto, precisamos desativar o _dropout_ durante a validação, teste e sempre que estivermos usando a rede para fazer previsões. Para fazer isso, você usa `model.eval()`. Isso define o modelo no modo de avaliação, onde a probabilidade de desistência é 0. Você pode reativar a desistência configurando o modelo no modo de treinamento com `model.train()`. Em geral, o padrão para o loop de validação será parecido com este, onde você desativa gradientes, configura o modelo para o modo de avaliação, calcula a perda e métrica de validação e, em seguida, configura o modelo novamente para o modo de treinamento.\n",
        "\n",
        "```python\n",
        "# desligue os gradientes\n",
        "with torch.no_grad():\n",
        "    \n",
        "    # ative o modo de avaliação do modelo\n",
        "    model.eval()\n",
        "    \n",
        "    # passe de validação aqui\n",
        "    for images, labels in testloader:\n",
        "        ...\n",
        "\n",
        "# ative novamente o modo de treino\n",
        "model.train()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jlfu2aufBJmR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA não disponível.  Treinando na CPU ...')\n",
        "else:\n",
        "    print('CUDA disponível!  Treinando na GPU ...')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6yoQXWEMeiD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: Crie seu modelo com Dropout de probabilidade de 25%\n",
        "model = \n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
        "\n",
        "epochs = 2\n",
        "test_loss_min = np.Inf\n",
        "begin = time.time()\n",
        "\n",
        "if train_on_gpu:\n",
        "    model.to(device)\n",
        "\n",
        "train_losses, test_losses = [], []\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in trainloader:\n",
        "        if train_on_gpu:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "        images = images.view(images.shape[0], -1)\n",
        "        optimizer.zero_grad()\n",
        "        log_ps = model(images)\n",
        "        loss = criterion(log_ps, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    else:\n",
        "        test_loss = 0\n",
        "        accuracy = 0\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            for images, labels in testloader:\n",
        "                if train_on_gpu:\n",
        "                    images = images.to(device)\n",
        "                    labels = labels.to(device)\n",
        "                images = images.view(images.shape[0], -1)\n",
        "                log_ps = model(images)\n",
        "                test_loss += criterion(log_ps, labels)\n",
        "                ps = torch.exp(log_ps)\n",
        "                top_p, top_class = ps.topk(1, dim=1)\n",
        "                equals = top_class == labels.view(*top_class.shape)\n",
        "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
        "        model.train()\n",
        "        train_losses.append(running_loss/len(trainloader))\n",
        "        test_losses.append(test_loss/len(testloader))\n",
        "    if test_loss <= test_loss_min:\n",
        "        print('Perda de teste caiu !({:.6f} --> {:.6f}).  Salvando modelo...'.format(\n",
        "        test_loss_min,\n",
        "        test_loss))\n",
        "        torch.save(model.state_dict(), 'model.pt')\n",
        "        test_loss_min = test_loss\n",
        "    print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
        "              \"Perda de treino: {:.3f}.. \".format(running_loss/len(trainloader)),\n",
        "              \"Perda de teste: {:.3f}.. \".format(test_loss/len(testloader)),\n",
        "              \"Precisão de teste: {:.3f}\".format(accuracy/len(testloader)))\n",
        "print(time.time()-begin)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6-X08wT_ZQ1",
        "colab_type": "text"
      },
      "source": [
        "## Inferência\n",
        "\n",
        "Agora que o modelo foi treinado, podemos usá-lo para inferência. Já fizemos isso antes, mas agora precisamos lembrar de definir o modelo no modo de inferência com `model.eval()`. Você também deseja desativar o autograd no contexto `torch.no_grad()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPJ3D_tI_-od",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "# Função auxiliar para plotar a imagem\n",
        "def view_classify(img, ps, version=\"MNIST\"):\n",
        "    ps = ps.data.numpy().squeeze()\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
        "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
        "    ax1.axis('off')\n",
        "    ax2.barh(np.arange(10), ps)\n",
        "    ax2.set_aspect(0.1)\n",
        "    ax2.set_yticks(np.arange(10))\n",
        "    if version == \"MNIST\":\n",
        "        ax2.set_yticklabels(np.arange(10))\n",
        "    elif version == \"Fashion\":\n",
        "        ax2.set_yticklabels(['Camiseta',\n",
        "                             'Calças',\n",
        "                             'Pullover',\n",
        "                             'Vestido',\n",
        "                             'Casaco',\n",
        "                             'Sandália',\n",
        "                             'Camisa',\n",
        "                             'Tênis',\n",
        "                             'Bolsa',\n",
        "                             'Bota no tornozelo'], size='small');\n",
        "    ax2.set_title('Probabilidade de classe')\n",
        "    ax2.set_xlim(0, 1.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPqMUEA5_WHA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Teste sua rede!\n",
        "model.eval()\n",
        "\n",
        "dataiter = iter(testloader)\n",
        "images, labels = dataiter.next()\n",
        "img = images[0]\n",
        "# Converte imagem 2D para um tensor 1D\n",
        "img = img.view(1, 784)\n",
        "model.to(torch.device(\"cpu\"))\n",
        "\n",
        "# Calcule a probabilidade das classes\n",
        "with torch.no_grad():\n",
        "    output = model.forward(img)\n",
        "\n",
        "ps = torch.exp(output)\n",
        "\n",
        "# Plota imagem e probabilidades\n",
        "\n",
        "view_classify(img.resize_(1, 28, 28), ps, version='Fashion')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ovw5ZmASueq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}